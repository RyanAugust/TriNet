{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_open_data_ath = \"E:\\gc_opendata\\9787e81f-19f6-4cc1-891d-63e68b4d2f9f\"\n",
    "athlete_files = next(os.walk(sample_open_data_ath), (None, None, []))[2]\n",
    "# [athlete_files.remove(file) if '.csv' not in file else None for file in athlete_files]\n",
    "# athlete_activity_filepaths = [os.path.join(sample_open_data_ath,filepath) for filepath in athlete_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sample_open_data_ath,'{9787e81f-19f6-4cc1-891d-63e68b4d2f9f}.json'),'r') as f:\n",
    "    ath_over = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = json.loads(ath_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['RIDES'][0]['METRICS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['RIDES'][500]['METRICS']['cp_setting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class athlete(object):\n",
    "    def __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xspeed(x, secs_id, dist_id, elev_id):\n",
    "    xspeed = (\n",
    "        1+9*(                                  # slope adj\n",
    "            (x[elev_id,1:] - x[elev_id,:-1]) / # delta alt\n",
    "            (x[dist_id,1:] - x[dist_id,:-1])   # delta dist\n",
    "        )\n",
    "    ) * (\n",
    "            (x[dist_id,1:] - x[dist_id,:-1]) / # delta dist\n",
    "            (x[secs_id,1:] - x[secs_id,:-1])   # delta secs\n",
    "            * (60*60)                          # convert to kph\n",
    "        )                                      # slope running speed\n",
    "    return xspeed\n",
    "\n",
    "def extract_activity(filepath, metrics, make_relative=True, make_xspeed=False):\n",
    "    df = pd.read_csv(filepath, engine='pyarrow')\n",
    "    activity_array = df[metrics].to_numpy().T\n",
    "    if make_xspeed:\n",
    "        xspeed = calc_xspeed(activity_array, metrics.index('secs'), metrics.index('km'), metrics.index('alt'))\n",
    "        xspeed = np.concatenate((np.array([0]),xspeed))\n",
    "        activity_array = np.concatenate((activity_array,[xspeed]), axis=0)\n",
    "    return activity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = athlete_activity_filepaths[100]\n",
    "metrics = ['power','hr','km','alt','secs']\n",
    "extract_activity(filepath, metrics, make_xspeed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.hidden_1 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.output = nn.Linear(in_features=16, out_features=output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        return self.output(x)\n",
    "    \n",
    "    \n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_accuracies, test_accuracies = [], []\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train set\n",
    "    for X, y in train_loader:\n",
    "        preds = model(X)\n",
    "        pred_labels = torch.argmax(preds, axis=1)\n",
    "        loss = loss_function(preds, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracies.append(\n",
    "        100 * torch.mean((pred_labels == y).float()).item()\n",
    "    )\n",
    "    \n",
    "    # Test set\n",
    "    X, y = next(iter(test_loader))\n",
    "    pred_labels = torch.argmax(model(X), axis=1)\n",
    "    test_accuracies.append(\n",
    "        100 * torch.mean((pred_labels == y).float()).item()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "450c6c939a91a13d43daedb0706b943ba15a63d2bd7aa1f53ffd849b7045dd1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
